{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack Tests remade (23.01.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from art import config\n",
    "from art.utils import load_dataset, get_file\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from art.defences.trainer import AdversarialTrainerMadryPGD\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = 'assets/models_mu/'\n",
    "adv_models_mu = {}\n",
    "for adv_model in os.listdir(folder_path):\n",
    "    if '.h5' in adv_model:\n",
    "        id = adv_model.split('_')[-1].split('.')[0]\n",
    "        adv_models_mu[id] = load_model(folder_path + adv_model)\n",
    "\n",
    "folder_path = 'assets/models_mu_transform/'\n",
    "adv_models_mu_transform = {}\n",
    "for adv_model in os.listdir(folder_path):\n",
    "    if '.h5' in adv_model:\n",
    "        id = adv_model.split('_')[-1].split('.')[0]\n",
    "        adv_models_mu_transform[id] = load_model(folder_path + adv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "adv_models_mu = dict(sorted(adv_models_mu.items()))\n",
    "adv_models_mu_transform = dict(sorted(adv_models_mu_transform.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('assets/models/mnist_zico.h5')\n",
    "model_madry = tf.keras.models.load_model('assets/models/mnist_madry_zico_model.h5')\n",
    "model_adv = tf.keras.models.load_model('assets/models/mnist_adv_model.h5')\n",
    "model_adv_v2 = tf.keras.models.load_model('assets/models/mnist_adv_model_v2.h5')\n",
    "model_adv_v3 = tf.keras.models.load_model('assets/models/mnist_adv_model_v3.h5')\n",
    "model_adv_v3_2 = tf.keras.models.load_model('assets/models/mnist_adv_model_v3_2.h5')\n",
    "model_adv_v4 = tf.keras.models.load_model('assets/models/mnist_adv_model_v4.h5')\n",
    "model_adv_v5 = tf.keras.models.load_model('assets/models/mnist_adv_model_v5.h5')\n",
    "model_adv_v6 = tf.keras.models.load_model('assets/models/mnist_adv_model_v6.h5')\n",
    "model_adv_v6 = tf.keras.models.load_model('assets/models/mnist_adv_model_v6.h5')\n",
    "# model_final = tf.keras.models.load_model('research/models/mnist_adv_model_final.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "(x_art_train, y_art_train), (x_art_test, y_art_test), min_, max_ = load_dataset('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# resize x_train and x_test\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGD, FGSM and SPSA Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 28, 28, 1)\n",
      "(140000, 1)\n",
      "(140000, 28, 28, 1)\n",
      "(140000, 1)\n",
      "(400, 28, 28, 1)\n",
      "(400, 1)\n"
     ]
    }
   ],
   "source": [
    "# load fgsm and pgd images and labels\n",
    "# import fgsm and pgd adversarial sampels\n",
    "pgd_images_zico = np.load('assets/pgd_images_zico.npz')['images']\n",
    "pgd_labels_zico = np.load('assets/pgd_images_zico.npz')['labels']\n",
    "pgd_labels_zico_onehot = np.take(np.eye(10, dtype=np.float32), pgd_labels_zico, axis=0)\n",
    "\n",
    "fgsm_images_zico = np.load('assets/fgsm_images_zico.npz')['images']\n",
    "fgsm_labels_zico = np.load('assets/fgsm_images_zico.npz')['labels']\n",
    "fgsm_labels_zico_onehot = np.take(np.eye(10, dtype=np.float32), fgsm_labels_zico, axis=0)\n",
    "\n",
    "spsa_images_zico = np.load('assets/spsa_images_zico.npz')['images']\n",
    "spsa_labels_zico = np.load('assets/spsa_images_zico.npz')['labels']\n",
    "spsa_labels_zico_onehot = np.take(np.eye(10), spsa_labels_zico.astype(np.int64), axis=0)\n",
    "\n",
    "# reshape pgd and fgsm images to 28, 28, 1\n",
    "pgd_images_zico = np.reshape(pgd_images_zico, (len(pgd_images_zico), 28, 28, 1))\n",
    "fgsm_images_zico = np.reshape(fgsm_images_zico, (len(fgsm_images_zico), 28, 28, 1))\n",
    "spsa_images_zico = np.reshape(spsa_images_zico, (len(spsa_images_zico), 28, 28, 1))\n",
    "\n",
    "print(pgd_images_zico.shape)\n",
    "print(pgd_labels_zico.shape)\n",
    "print(fgsm_images_zico.shape)\n",
    "print(fgsm_labels_zico.shape)   \n",
    "print(spsa_images_zico.shape)\n",
    "print(spsa_labels_zico.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     1     2     3     4     5     6     7     8     9]\n",
      " [13720 15890 14448 14140 13748 12488 13412 14392 13636 14126]]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(fgsm_images_zico[10000], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# show the first 1000 unique labels and counts\n",
    "unique, counts = np.unique(fgsm_labels_zico, return_counts=True)\n",
    "print(np.asarray((unique, counts)))\n",
    "\n",
    "# take the first 10000 labels and images because higher epsilon values make the image unrecognizable\n",
    "fgsm_images_zico = fgsm_images_zico[:10000]\n",
    "fgsm_labels_zico = fgsm_labels_zico[:10000]\n",
    "fgsm_labels_zico_onehot = fgsm_labels_zico_onehot[:10000]\n",
    "\n",
    "# squeeze fgsm_labels_zico and pgd_labels_zico to remove the extra dimension\n",
    "fgsm_labels_zico = np.squeeze(fgsm_labels_zico)\n",
    "fgsm_labels_zico_onehot = fgsm_labels_zico_onehot.reshape(-1, 10)\n",
    "pgd_labels_zico = np.squeeze(pgd_labels_zico)\n",
    "pgd_labels_zico_onehot = pgd_labels_zico_onehot.reshape(-1, 10)\n",
    "spsa_labels_zico = np.squeeze(spsa_labels_zico)\n",
    "spsa_labels_zico_onehot = spsa_labels_zico_onehot.reshape(-1, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIM Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(10000,)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# load images and labels\n",
    "# import adversarial sampels\n",
    "bim_images = np.load('assets/bim_images.npz')['images']\n",
    "bim_labels = np.load('assets/bim_images.npz')['labels']\n",
    "bim_labels_onehot = np.take(np.eye(10), bim_labels.astype(np.int64), axis=0)\n",
    "\n",
    "\n",
    "# reshape images to 28, 28, 1\n",
    "bim_images = np.reshape(bim_images, (len(bim_images), 28, 28, 1))\n",
    "\n",
    "print(bim_images.shape)\n",
    "print(bim_labels.shape)\n",
    "print(bim_labels_onehot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrestricted Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94372, 28, 28, 1)\n",
      "(94372,)\n",
      "(94372, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load mnist_adv dataset\n",
    "# adv_path = 'assets/data/mnist_adv/'\n",
    "adv_path = 'assets/mnist_zico_defense_by_attack_with_z0/'\n",
    "adv_files = []\n",
    "unrestricted_img = []\n",
    "unrestricted_label = []\n",
    "\n",
    "# for loop to load all the images\n",
    "for source in range(10):\n",
    "    for target in range(10):\n",
    "        if(source != target):\n",
    "            file = np.load(adv_path + 'from' + str(source) + 'to' + str(target) + '.npz')\n",
    "            adv_files.append(file)\n",
    "            unrestricted_label.extend(np.full(len(file['adv_imgs']), source).tolist())\n",
    "\n",
    "keys = adv_files[0].files\n",
    "\n",
    "for file in adv_files:\n",
    "    with file as data:\n",
    "        unrestricted_img.extend(data[keys[0]])\n",
    "\n",
    "unrestricted_img = np.array(unrestricted_img)\n",
    "unrestricted_label = np.array(unrestricted_label)\n",
    "y_one_hot = np.take(np.eye(10), unrestricted_label, axis=0)\n",
    "\n",
    "plt.imshow(unrestricted_img[0], cmap='gray')\n",
    "plt.show()\n",
    "print(unrestricted_img.shape)\n",
    "print(unrestricted_label.shape)\n",
    "print(y_one_hot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 28, 28, 1)\n",
      "(400, 1)\n",
      "(400, 10)\n"
     ]
    }
   ],
   "source": [
    "# load images and labels\n",
    "# import adversarial sampels\n",
    "mim_images = np.load('assets/mim_images_zico.npz')['images']\n",
    "mim_labels = np.load('assets/mim_images_zico.npz')['labels']\n",
    "mim_labels_onehot = np.take(np.eye(10), mim_labels.astype(np.int64), axis=0)\n",
    "mim_labels_onehot = mim_labels_onehot.reshape(-1, 10)\n",
    "\n",
    "# reshape images to 28, 28, 1\n",
    "mim_images = np.reshape(mim_images, (len(mim_images), 28, 28, 1))\n",
    "\n",
    "print(mim_images.shape)\n",
    "print(mim_labels.shape)\n",
    "print(mim_labels_onehot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Attacks\n",
    "(for attacks that have not been generated and saved locally)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIM (using cleverhans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from cleverhans.tf2.attacks.momentum_iterative_method import momentum_iterative_method\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Define the input placeholder\n",
    "x_0 = tf.convert_to_tensor(np.array([train_images[0]]), dtype='float32')\n",
    "y_0 = tf.convert_to_tensor(np.array(train_labels[0]), dtype='float32')\n",
    "\n",
    "# Define the logits of the model\n",
    "logits_model = tf.keras.Model(model.input,model.layers[-1].output)\n",
    "\n",
    "\n",
    "# Define the attack parameters\n",
    "eps = 0.5\n",
    "eps_iter = 0.01\n",
    "nb_iter = 40\n",
    "clip_min = 0.0\n",
    "clip_max = 1.0\n",
    "\n",
    "# Generate adversarial examples\n",
    "adv_x = momentum_iterative_method(logits_model, x = x_0, eps = eps, nb_iter = nb_iter, clip_min=clip_min, clip_max=clip_max, sanity_checks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_x_image = tf.keras.backend.get_value(adv_x)\n",
    "adv_x_image = np.reshape(adv_x_image, (28, 28, 1))\n",
    "\n",
    "plt.imshow(adv_x_image, cmap='gray')\n",
    "plt.show()\n",
    "tf.keras.backend.get_value(y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "preds_adv_2 = model_adv(adv_x)\n",
    "tf.keras.backend.get_value(tf.argmax(preds_adv_2, axis=-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [ 8 14  8 11 14  7 10 15  2 11]]\n"
     ]
    }
   ],
   "source": [
    "test_images_gen = test_images[:100]\n",
    "test_labels_gen = test_labels[:100]\n",
    "unique, counts = np.unique(test_labels_gen, return_counts=True)\n",
    "print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 28, 28)\n",
      "0.1\n",
      "0.2\n",
      "0.30000000000000004\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# calculate error rate for FGSM attack on both clean and adv model with varying epsilon values\n",
    "\n",
    "# iterate from 0.1 to 1.5 with 0.1 step size\n",
    "epsilon_values = np.arange(0.1, 0.4, 0.1)\n",
    "mim_images = []\n",
    "mim_labels = []\n",
    "\n",
    "print(test_images_gen.shape)\n",
    "\n",
    "for index, epsilon in enumerate(epsilon_values):\n",
    "    print(epsilon)\n",
    "\n",
    "    # original image and original label\n",
    "\n",
    "    for i in range(test_images_gen.shape[0]): \n",
    "        original_image = test_images_gen[i]\n",
    "        original_image = tf.convert_to_tensor(original_image.reshape((1,28,28)), dtype='float32') #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
    "\n",
    "        original_label = test_labels_gen[i]\n",
    "        original_label = np.reshape(original_label, (1,)).astype('float32') # Give label proper shape and type for cleverhans\n",
    "\n",
    "        \n",
    "        # perform spsa on train_images\n",
    "        adv_example = momentum_iterative_method(logits_model, x = original_image, eps = epsilon, nb_iter = 10, clip_min=0.0, clip_max=1.0, sanity_checks=False)\n",
    "        adv_example = tf.keras.backend.get_value(adv_example)\n",
    "        \n",
    "        # add fgsm image to list\n",
    "        mim_images.append(adv_example)\n",
    "        mim_labels.append(original_label)\n",
    "\n",
    "np.savez('mim_images_zico', images=mim_images, labels=mim_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGD (ε ≃ 0.7) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carlini Wagner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from cleverhans.tf2.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# Define the input placeholder\n",
    "x_0 = tf.convert_to_tensor(np.array([train_images[0]]), dtype='float32')\n",
    "y_0 = tf.convert_to_tensor(np.array(train_labels[0]), dtype='float32')\n",
    "\n",
    "# Define the logits of the model\n",
    "logits_model = tf.keras.Model(model.input,model.layers[-1].output)\n",
    "\n",
    "# Generate adversarial examples\n",
    "adv_x = carlini_wagner_l2(logits_model, x = x_0, learning_rate=0.1, max_iterations=100, initial_const=0, binary_search_steps=50, confidence=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_x_image = tf.keras.backend.get_value(adv_x)\n",
    "adv_x_image = np.reshape(adv_x_image, (28, 28, 1))\n",
    "\n",
    "plt.imshow(adv_x_image, cmap='gray')\n",
    "plt.show()\n",
    "tf.keras.backend.get_value(y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_adv_2 = model(adv_x)\n",
    "tf.keras.backend.get_value(tf.argmax(preds_adv_2, axis=-1))[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test attack on Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.153\n",
      "model_madry accuracy: 0.974\n",
      "model_adv accuracy: 0.984\n",
      "model_adv_v2 accuracy: 0.977\n",
      "model_adv_v3 accuracy: 0.986\n",
      "model_adv_v3_2 accuracy: 0.871\n",
      "model_adv_v4 accuracy: 0.985\n",
      "model_adv_v5 accuracy: 0.985\n",
      "model_adv_v6 accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "print('model accuracy: %.3f' % model.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])\n",
    "print('model_madry accuracy: %.3f' % model_madry.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])\n",
    "print('model_adv accuracy: %.3f' % model_adv.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v2 accuracy: %.3f' % model_adv_v2.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v3 accuracy: %.3f' % model_adv_v3.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v3_2 accuracy: %.3f' % model_adv_v3_2.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v4 accuracy: %.3f' % model_adv_v4.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v5 accuracy: %.3f' % model_adv_v5.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v6 accuracy: %.3f' % model_adv_v6.evaluate(fgsm_images_zico, fgsm_labels_zico, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model z: 0.101\n",
      "Model z0: 0.101\n",
      "Model z2: 0.101\n",
      "Model z3: 0.984\n",
      "Model z4: 0.101\n",
      "Model z5: 0.113\n",
      "Model z6: 0.983\n",
      "Model z7: 0.101\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu[key].evaluate(fgsm_images_zico, fgsm_labels_zico_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Albumentation Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model: 0.797\n",
      "Model z: 0.966\n",
      "Model z0: 0.964\n",
      "Model z2: 0.969\n",
      "Model z3: 0.967\n",
      "Model z4: 0.967\n",
      "Model z5: 0.966\n",
      "Model z6: 0.963\n",
      "Model z7: 0.966\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu_transform:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu_transform[key].evaluate(fgsm_images_zico, fgsm_labels_zico_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.220\n",
      "model_madry accuracy: 0.985\n",
      "model_adv accuracy: 0.988\n",
      "model_adv_v2 accuracy: 0.985\n",
      "model_adv_v3 accuracy: 0.988\n",
      "model_adv_v3_2 accuracy: 0.985\n",
      "model_adv_v4 accuracy: 0.988\n",
      "model_adv_v5 accuracy: 0.987\n",
      "model_adv_v6 accuracy: 0.986\n"
     ]
    }
   ],
   "source": [
    "print('model accuracy: %.3f' % model.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])\n",
    "print('model_madry accuracy: %.3f' % model_madry.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])\n",
    "print('model_adv accuracy: %.3f' % model_adv.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v2 accuracy: %.3f' % model_adv_v2.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v3 accuracy: %.3f' % model_adv_v3.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v3_2 accuracy: %.3f' % model_adv_v3_2.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v4 accuracy: %.3f' % model_adv_v4.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v5 accuracy: %.3f' % model_adv_v5.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v6 accuracy: %.3f' % model_adv_v6.evaluate(pgd_images_zico, pgd_labels_zico, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model z: 0.101\n",
      "Model z0: 0.101\n",
      "Model z2: 0.101\n",
      "Model z3: 0.988\n",
      "Model z4: 0.101\n",
      "Model z5: 0.113\n",
      "Model z6: 0.988\n",
      "Model z7: 0.101\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu[key].evaluate(pgd_images_zico, pgd_labels_zico_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Albumentation Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model: 0.911\n",
      "Model z: 0.971\n",
      "Model z0: 0.971\n",
      "Model z2: 0.974\n",
      "Model z3: 0.972\n",
      "Model z4: 0.971\n",
      "Model z5: 0.973\n",
      "Model z6: 0.971\n",
      "Model z7: 0.970\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu_transform:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu_transform[key].evaluate(pgd_images_zico, pgd_labels_zico_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on SPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.377\n",
      "model_madry accuracy: 0.965\n",
      "model_adv accuracy: 0.980\n",
      "model_adv_v2 accuracy: 0.983\n",
      "model_adv_v3 accuracy: 0.980\n",
      "model_adv_v3_2 accuracy: 0.947\n",
      "model_adv_v4 accuracy: 0.985\n",
      "model_adv_v5 accuracy: 0.983\n",
      "model_adv_v6 accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "print('model accuracy: %.3f' % model.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])\n",
    "print('model_madry accuracy: %.3f' % model_madry.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])\n",
    "print('model_adv accuracy: %.3f' % model_adv.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v2 accuracy: %.3f' % model_adv_v2.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v3 accuracy: %.3f' % model_adv_v3.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v3_2 accuracy: %.3f' % model_adv_v3_2.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v4 accuracy: %.3f' % model_adv_v4.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v5 accuracy: %.3f' % model_adv_v5.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])\n",
    "print('model_adv_v6 accuracy: %.3f' % model_adv_v6.evaluate(spsa_images_zico, spsa_labels_zico, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model z: 0.110\n",
      "Model z0: 0.110\n",
      "Model z2: 0.110\n",
      "Model z3: 0.993\n",
      "Model z4: 0.110\n",
      "Model z5: 0.140\n",
      "Model z6: 0.998\n",
      "Model z7: 0.110\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu[key].evaluate(spsa_images_zico, spsa_labels_zico_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Albumentation Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model: 0.505\n",
      "Model z: 0.952\n",
      "Model z0: 0.980\n",
      "Model z2: 0.978\n",
      "Model z3: 0.952\n",
      "Model z4: 0.955\n",
      "Model z5: 0.978\n",
      "Model z6: 0.967\n",
      "Model z7: 0.955\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu_transform:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu_transform[key].evaluate(spsa_images_zico, spsa_labels_zico_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on MIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.157\n",
      "model_madry accuracy: 0.935\n",
      "model_adv accuracy: 0.947\n",
      "model_adv_v2 accuracy: 0.848\n",
      "model_adv_v3 accuracy: 0.925\n",
      "model_adv_v3_2 accuracy: 0.892\n",
      "model_adv_v4 accuracy: 0.925\n",
      "model_adv_v5 accuracy: 0.938\n",
      "model_adv_v6 accuracy: 0.940\n"
     ]
    }
   ],
   "source": [
    "print('model accuracy: %.3f' % model.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "print('model_madry accuracy: %.3f' % model_madry.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "print('model_adv accuracy: %.3f' % model_adv.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "print('model_adv_v2 accuracy: %.3f' % model_adv_v2.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "print('model_adv_v3 accuracy: %.3f' % model_adv_v3.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "print('model_adv_v3_2 accuracy: %.3f' % model_adv_v3_2.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "print('model_adv_v4 accuracy: %.3f' % model_adv_v4.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "print('model_adv_v5 accuracy: %.3f' % model_adv_v5.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "print('model_adv_v6 accuracy: %.3f' % model_adv_v6.evaluate(mim_images, mim_labels, verbose=0)[1])\n",
    "# print('model_final accuracy: %.3f' % model_final.evaluate(mim_images, mim_labels, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model z: 0.110\n",
      "Model z0: 0.110\n",
      "Model z2: 0.110\n",
      "Model z3: 0.942\n",
      "Model z4: 0.110\n",
      "Model z5: 0.140\n",
      "Model z6: 0.955\n",
      "Model z7: 0.110\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu[key].evaluate(mim_images, mim_labels_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Albumentation Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model: 0.377\n",
      "Model z: 0.940\n",
      "Model z0: 0.965\n",
      "Model z2: 0.960\n",
      "Model z3: 0.935\n",
      "Model z4: 0.947\n",
      "Model z5: 0.967\n",
      "Model z6: 0.965\n",
      "Model z7: 0.952\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu_transform:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu_transform[key].evaluate(mim_images, mim_labels_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.980\n",
      "model_madry accuracy: 0.717\n",
      "model_adv accuracy: 0.986\n",
      "model_adv_v2 accuracy: 0.979\n",
      "model_adv_v3 accuracy: 0.985\n",
      "model_adv_v3_2 accuracy: 0.758\n",
      "model_adv_v4 accuracy: 0.985\n",
      "model_adv_v5 accuracy: 0.989\n",
      "model_adv_v6 accuracy: 0.984\n",
      "model_final accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "print('model accuracy: %.3f' % model.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "print('model_madry accuracy: %.3f' % model_madry.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "print('model_adv accuracy: %.3f' % model_adv.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "print('model_adv_v2 accuracy: %.3f' % model_adv_v2.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "print('model_adv_v3 accuracy: %.3f' % model_adv_v3.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "print('model_adv_v3_2 accuracy: %.3f' % model_adv_v3_2.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "print('model_adv_v4 accuracy: %.3f' % model_adv_v4.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "print('model_adv_v5 accuracy: %.3f' % model_adv_v5.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "print('model_adv_v6 accuracy: %.3f' % model_adv_v6.evaluate(bim_images, bim_labels, verbose=0)[1])\n",
    "# print('model_final accuracy: %.3f' % model_final.evaluate(bim_images, bim_labels, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model z: 0.101\n",
      "Model z0: 0.101\n",
      "Model z2: 0.101\n",
      "Model z3: 0.988\n",
      "Model z4: 0.101\n",
      "Model z5: 0.113\n",
      "Model z6: 0.985\n",
      "Model z7: 0.101\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu[key].evaluate(bim_images, bim_labels_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Albumentation Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model: 0.371\n",
      "Model z: 0.941\n",
      "Model z0: 0.943\n",
      "Model z2: 0.951\n",
      "Model z3: 0.950\n",
      "Model z4: 0.952\n",
      "Model z5: 0.938\n",
      "Model z6: 0.964\n",
      "Model z7: 0.954\n"
     ]
    }
   ],
   "source": [
    "for key in adv_models_mu_transform:\n",
    "    print(\"Model %s: %.3f\" % (key, adv_models_mu_transform[key].evaluate(bim_images, bim_labels_onehot, verbose=0)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Unrestrcited Attack"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Training on Multiple version images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9cbd16962e41f69b3e5465ff3afa80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load mnist dataset\n",
    "ds_train_images = []\n",
    "ds_train_labels = []\n",
    "\n",
    "for images, labels in ds_train.unbatch():\n",
    "  ds_train_images.append(images)\n",
    "  ds_train_labels.append(labels)\n",
    "\n",
    "ds_train_images = np.array(ds_train_images)\n",
    "ds_train_labels = np.array(ds_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load mnist dataset\n",
    "ds_test_images = []\n",
    "ds_test_labels = []\n",
    "\n",
    "for images, labels in ds_test.unbatch():\n",
    "  ds_test_images.append(images)\n",
    "  ds_test_labels.append(labels)\n",
    "\n",
    "ds_test_images = np.array(ds_test_images)\n",
    "ds_test_labels = np.array(ds_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127917, 28, 28, 1)\n",
      "(127917,)\n"
     ]
    }
   ],
   "source": [
    "# load mnist_adv dataset\n",
    "# adv_path = 'assets/data/mnist_adv/'\n",
    "adv_paths = ['research/mnist_zico_defense_by_attack_with_z0/', 'research/mnist_zico_defense_by_attack_with_z3/', 'research/mnist_zico_defense_by_attack_with_z5/', 'research/mnist_zico_defense_by_attack_with_z6/']\n",
    "adv_files = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# for loop to load all the images\n",
    "for path in adv_paths: \n",
    "  for source in range(10):\n",
    "      for target in range(10):\n",
    "          if(source != target):\n",
    "            file = np.load(path + 'from' + str(source) + 'to' + str(target) + '.npz')\n",
    "            adv_files.append(file)\n",
    "            y.extend(np.full(len(file['adv_imgs']), source).tolist())\n",
    "\n",
    "keys = adv_files[0].files\n",
    "\n",
    "for file in adv_files:\n",
    "  with file as data:\n",
    "      X.extend(data[keys[0]])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y_one_hot = np.take(np.eye(10), y, axis=0)\n",
    "\n",
    "plt.imshow(X[0], cmap='gray')\n",
    "plt.show()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# split X into 70-30 train-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89541, 28, 28, 1) (60000, 28, 28, 1)\n",
      "(149541, 28, 28, 1) (149541,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, ds_train_images.shape)\n",
    "\n",
    "ds_train_adv_images = np.concatenate((ds_train_images, X_train), axis=0)\n",
    "ds_train_adv_labels = np.concatenate((ds_train_labels, y_train), axis=0)\n",
    "\n",
    "print(ds_train_adv_images.shape, ds_train_adv_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38376, 28, 28, 1) (10000, 28, 28, 1)\n",
      "(48376, 28, 28, 1) (48376,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, ds_test_images.shape)\n",
    "\n",
    "ds_test_adv_images = np.concatenate((ds_test_images, X_test), axis=0)\n",
    "ds_test_adv_labels = np.concatenate((ds_test_labels, y_test), axis=0)\n",
    "\n",
    "print(ds_test_adv_images.shape, ds_test_adv_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4674/4674 [==============================] - 23s 5ms/step - loss: 0.0679 - accuracy: 0.9807\n",
      "Epoch 2/10\n",
      "4674/4674 [==============================] - 23s 5ms/step - loss: 0.0248 - accuracy: 0.9935\n",
      "Epoch 3/10\n",
      "4674/4674 [==============================] - 22s 5ms/step - loss: 0.0162 - accuracy: 0.9955\n",
      "Epoch 4/10\n",
      "4674/4674 [==============================] - 23s 5ms/step - loss: 0.0115 - accuracy: 0.9967\n",
      "Epoch 5/10\n",
      "4674/4674 [==============================] - 22s 5ms/step - loss: 0.0082 - accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "4674/4674 [==============================] - 23s 5ms/step - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 7/10\n",
      "4674/4674 [==============================] - 23s 5ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "4674/4674 [==============================] - 22s 5ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 9/10\n",
      "4674/4674 [==============================] - 23s 5ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 10/10\n",
      "4674/4674 [==============================] - 23s 5ms/step - loss: 0.0038 - accuracy: 0.9988\n",
      "1512/1512 [==============================] - 5s 3ms/step - loss: 0.0215 - accuracy: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.021485043689608574, 0.9958657026290894]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequential model with conv2d 16, padding valid, relu -> conv2d 32, padding valid, relu -> softmax\n",
    "model_final = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=4, padding='valid', activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=4, padding='valid', activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# train on mnist\n",
    "model_final.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model_final.fit(\n",
    "    x = ds_train_adv_images,\n",
    "    y = ds_train_adv_labels,\n",
    "    epochs=10,\n",
    "    shuffle=True\n",
    ")\n",
    "model_final.evaluate(ds_test_adv_images, ds_test_adv_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save model_adv\n",
    "model_final.save('research/models/mnist_adv_model_final.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d32610e65d0ba547d20b5ddccd11b31c7d91644470808fb362c82b58c120951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
